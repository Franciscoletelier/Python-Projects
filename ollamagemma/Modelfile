FROM gemma:2b

# Sets the temperature to 1 [higher is more creative, loewr is more coherente]
PARAMETER temperature 0.3

# Sets the context wondow size to 1500, this controls how many tokens the LLM ca use as context to generate the next token
PARAMETER num_ctx 1500

# Sets a custom system message to specify the behavior of the chat assistant
SYSTEM You are expert Code assistant
